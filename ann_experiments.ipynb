{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET_FILE = \"random-xs-20-euclidean.hdf5\"\n",
    "#DATASET_FILE = \"random-s-100-euclidean.hdf5\"\n",
    "#DATASET_FILE = \"sift-128-euclidean.hdf5\"\n",
    "#DATASET_FILE = \"fashion-mnist-784-euclidean.hdf5\"\n",
    "#DATASET_FILE = \"mnist-784-euclidean.hdf5\"\n",
    "#DATASET_FILE = \"nytimes-16-angular.hdf5\"\n",
    "#DATASET_FILE = \"glove-100-angular.hdf5\"\n",
    "#DATASET_FILE = \"glove-25-angular.hdf5\"\n",
    "#DATASET_FILE = \"stackoverflow-512-angular.hdf5\"\n",
    "DATASET_FILE = \"imagenet-96-angular.hdf5\"\n",
    "\n",
    "num_queries = 10\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set of size (9990000 * 96)\n",
      "test set of size (10 * 96)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dataset = h5py.File(DATASET_FILE, 'r')\n",
    "        \n",
    "train_data = np.array(dataset['train'])\n",
    "d = train_data.shape[1]\n",
    "\n",
    "test_data = np.array(dataset['test'])[:num_queries]\n",
    "nn = np.array(dataset['neighbors'])[:num_queries]\n",
    "\n",
    "if DATASET_FILE.startswith(('glove-', 'stackoverflow-')):\n",
    "    train_data = preprocessing.normalize(train_data, axis=1, norm='l2')\n",
    "    test_data = preprocessing.normalize(test_data, axis=1, norm='l2')\n",
    "    \n",
    "print('train set of size (%d * %d)' % train_data.shape)\n",
    "print('test set of size (%d * %d)' % test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num principle components needed to explain 85% of variance: 76\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import neighbors\n",
    "\n",
    "PCA_DIMS = 96\n",
    "\n",
    "np.random.seed(0)\n",
    "small_data = train_data[0:1000000,]\n",
    "\n",
    "pca = decomposition.PCA(n_components=PCA_DIMS)\n",
    "pca.fit(small_data)\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "effective_dim = sum(cumsum < 0.95)\n",
    "print(\"num principle components needed to explain {}% of variance: {}\".format(85, effective_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "small_data=train_data[0:1000,]\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=100, n_init=1, max_iter=10).fit(small_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2688719017475926"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.inertia_ / len(small_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8191890743068858"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([math.sqrt(np.linalg.norm(kmeans.cluster_centers_[7,] - x)) for x in kmeans.cluster_centers_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(indices, nn):\n",
    "    recall = []\n",
    "    for i in range(0, len(indices)):\n",
    "        knn = nn[i,:k]\n",
    "        overlap = np.intersect1d(indices[i], knn)\n",
    "        recall.append(len(overlap) / k)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kd-forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "\n",
    "kd_forest = neighbors.KDForest(train_data, n_trees=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QPS: 2.05\n",
      "recall: 1.0\n",
      "average dist comps: 267112.90\n"
     ]
    }
   ],
   "source": [
    "all_indices = []\n",
    "\n",
    "kd_forest.reset_dist_comps()\n",
    "start = time.time()\n",
    "for point in test_data:\n",
    "    test_point = np.array([point]).astype(np.double)\n",
    "    _, indices = kd_forest.query(np.array(test_point), k=k, max_dist_comps=500000, tree_index=-1)\n",
    "    all_indices.append(indices[0])\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"QPS: {:.2f}\".format(test_data.shape[0] / elapsed))\n",
    "\n",
    "recall = compute_recall(all_indices, nn)\n",
    "print(\"recall:\", np.mean(recall))\n",
    "    \n",
    "print(\"average dist comps: {:.2f}\".format(kd_forest.get_dist_comps() / test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "rotation1 = sp.stats.special_ortho_group.rvs(train_data.shape[1])\n",
    "rotation2 = sp.stats.special_ortho_group.rvs(train_data.shape[1])\n",
    "\n",
    "X_rot = np.zeros((2, train_data.shape[1]))\n",
    "train_data_rot1 = np.dot(train_data, rotation1)\n",
    "train_data_rot2 = np.dot(train_data, rotation2)\n",
    "\n",
    "test_point = np.array([test_data[0]])\n",
    "\n",
    "X_rot[0,:] = np.dot(test_point, rotation1)\n",
    "X_rot[1,:] = np.dot(test_point, rotation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_rot = np.linalg.norm(train_data_rot2 - X_rot[1,:], axis=1)\n",
    "dist = np.linalg.norm(train_data - test_point, axis=1)\n",
    "\n",
    "sum(abs(dist_rot - dist)) / train_data.shape[0]\n",
    "#sum(abs(dist)) / train_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn kd-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "kd_tree = neighbors.KDTree(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QPS: 5.13\n",
      "recall: 0.91\n",
      "average dist comps: 500032.00\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "all_indices = []\n",
    "total_dist_comps = 0\n",
    "for point in test_data:\n",
    "    dist, indices = kd_tree.query([point], k=k, breadth_first=True, max_dist_comps=500000)\n",
    "    all_indices.append(indices[0])\n",
    "    \n",
    "    total_dist_comps += kd_tree.get_n_calls() + kd_tree.get_tree_stats()[2]\n",
    "    kd_tree.reset_n_calls()\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"QPS: {:.2f}\".format(test_data.shape[0] / elapsed))\n",
    "\n",
    "recall = compute_recall(all_indices, nn)\n",
    "print(\"recall:\", np.mean(recall))\n",
    "print(\"average dist comps: {:.2f}\".format(total_dist_comps / test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_indices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn ball tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "np.random.seed(0)\n",
    "ball_tree = neighbors.BallTree(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, indices = ball_tree.query(test_data, k=k)\n",
    "recall = compute_recall(indices, nn)\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + kd-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import neighbors\n",
    "\n",
    "PCA_DIMS = 32\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "pca = decomposition.PCA(n_components=PCA_DIMS)\n",
    "train_data_pca = pca.fit_transform(train_data)\n",
    "\n",
    "kd_tree_pca = neighbors.KDTree(train_data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "test_data_pca = pca.transform(test_data)\n",
    "\n",
    "all_indices = []\n",
    "for i in range(len(test_data)):\n",
    "    point = test_data[i]\n",
    "    point_pca = test_data_pca[i]\n",
    "    \n",
    "    _, indices = kd_tree_pca.query([point_pca], k=100, breadth_first=True, max_candidates=100000)\n",
    "    indices = indices[0]\n",
    "    dists = np.linalg.norm(train_data[indices] - point, axis=1)\n",
    "\n",
    "    nearest_dists = np.argpartition(dists, k)[:k]\n",
    "    all_indices.append(indices[nearest_dists])\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"QPS: {:.2f}\".format(test_data.shape[0] / elapsed))\n",
    "\n",
    "recall = compute_recall(all_indices, nn)\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.linalg.norm(train_data[indices] - test_data[0], axis=1)\n",
    "dists\n",
    "nearest_dists = np.argpartition(dists, k)[:k]\n",
    "nearest_dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_pca.shape)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"explained variance at {}: {}\".format(32, cumsum[32 - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random projections + kd-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import random_projection\n",
    "\n",
    "NUM_PROJECTIONS = 8\n",
    "PROJECTION_DIMS = 8\n",
    "\n",
    "kd_trees = []\n",
    "projections = []\n",
    "\n",
    "for p in range(NUM_PROJECTIONS):\n",
    "    projection = random_projection.SparseRandomProjection(n_components=PROJECTION_DIMS)\n",
    "    projections.append(projection)\n",
    "    \n",
    "    train_data_proj = projection.fit_transform(train_data)\n",
    "    kd_tree = neighbors.KDTree(train_data_proj)\n",
    "    kd_trees.append(kd_tree)\n",
    "\n",
    "print(\"num projections: {}\".format(len(kd_trees)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "NUM_PROJECTIONS=8\n",
    "\n",
    "test_data_proj = []\n",
    "for p in range(NUM_PROJECTIONS):\n",
    "    projection = projections[p]\n",
    "    test_data_proj.append(projection.transform(test_data))\n",
    "\n",
    "start = time.time()\n",
    "for i in range(test_data.shape[0]):\n",
    "    candidates = []\n",
    "    for p in range(NUM_PROJECTIONS):\n",
    "        point_proj = test_data_proj[p][i]\n",
    "        \n",
    "        kd_tree = kd_trees[p]\n",
    "        _, result = kd_tree.query([point_proj], k=100, breadth_first=True, max_candidates=100000)\n",
    "        candidates.extend(result[0])\n",
    "\n",
    "    indices.append(candidates)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"QPS: {:.2f}\".format(test_data.shape[0] / elapsed))\n",
    "\n",
    "recall = compute_recall(indices, nn)\n",
    "print(\"recall:\", np.mean(recall))\n",
    "print(kd_tree.get_tree_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_tree.get_tree_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    indices.append([])\n",
    "    for p in range(NUM_PROJECTIONS):\n",
    "        indices_proj = candidates[p]\n",
    "        indices[i].extend(indices_proj)\n",
    "\n",
    "recall = compute_recall(indices, nn)\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random rotations + kd-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "NUM_ROTATIONS = 8\n",
    "\n",
    "np.random.seed(0)\n",
    "kd_trees = []\n",
    "rotations = []\n",
    "\n",
    "ortho_group = sp.stats.special_ortho_group\n",
    "\n",
    "for p in range(NUM_ROTATIONS):\n",
    "    rotation = ortho_group.rvs(train_data.shape[1])\n",
    "    rotations.append(rotation)\n",
    "\n",
    "    train_data_rot = np.dot(train_data, rotation)\n",
    "\n",
    "    kd_tree = neighbors.KDTree(train_data_rot, leaf_size=1000)\n",
    "    kd_trees.append(kd_tree)\n",
    "\n",
    "print(\"num rotations: {}\".format(len(kd_trees)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "NUM_ROTATIONS=8\n",
    "\n",
    "test_data_rot = []\n",
    "for r in range(NUM_ROTATIONS):\n",
    "    rotation = rotations[r]\n",
    "    test_data_rot.append(np.dot(test_data, rotation))\n",
    "\n",
    "start = time.time()\n",
    "for i in range(test_data.shape[0]):\n",
    "    candidates = []\n",
    "    for r in range(NUM_ROTATIONS):\n",
    "        point_rot = test_data_rot[r][i]\n",
    "        \n",
    "        kd_tree = kd_trees[r]\n",
    "        _, result = kd_tree.query([point_rot], k=100, breadth_first=False, max_candidates=5000)\n",
    "        candidates.extend(result[0])\n",
    "\n",
    "    indices.append(candidates)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"QPS: {:.2f}\".format(test_data.shape[0] / elapsed))\n",
    "\n",
    "recall = compute_recall(indices, nn)\n",
    "print(\"recall:\", np.mean(recall))\n",
    "print(kd_tree.get_tree_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variance-weighted projections + kd-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "train_data_var = np.var(train_data, axis=0, keepdims=True)\n",
    "train_data_var = preprocessing.normalize(train_data_var, axis=1, norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROJECTIONS = 4\n",
    "PROJECTION_DIMS = 32\n",
    "\n",
    "kd_trees = []\n",
    "projections = []\n",
    "\n",
    "for p in range(NUM_PROJECTIONS):\n",
    "    dims = np.random.choice(d, PROJECTION_DIMS, replace=False, p=train_data_var[0])\n",
    "    projections.append(dims)\n",
    "    \n",
    "    train_data_proj = train_data[:,dims]\n",
    "    kd_tree = neighbors.KDTree(train_data_proj)\n",
    "    kd_trees.append(kd_tree)\n",
    "\n",
    "print(\"num projections: {}\".format(len(kd_trees)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "start = time.time()\n",
    "\n",
    "for p in range(NUM_PROJECTIONS):\n",
    "    dims = projections[p]\n",
    "    kd_tree = kd_trees[p]\n",
    "    \n",
    "    test_data_proj = test_data[:,dims]\n",
    "    dist, indices = kd_tree.query(test_data_proj, k=100)\n",
    "    \n",
    "    candidates.append(indices)\n",
    "    \n",
    "elapsed = time.time() - start\n",
    "print(\"time: {:.2f} sec\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    indices.append([])\n",
    "    for p in range(NUM_PROJECTIONS):\n",
    "        indices_proj = candidates[p]\n",
    "        indices[i].extend(indices_proj)\n",
    "\n",
    "recall = compute_recall(indices, nn)\n",
    "print(np.mean(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
